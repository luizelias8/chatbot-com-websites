import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from dotenv import load_dotenv
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# Carrega as vari√°veis de ambiente
load_dotenv()

def inicializar_modelo_llm():
    # Inicializa o modelo de linguagem
    return ChatGroq(
        model='llama-3.3-70b-versatile', # Modelo LLM a ser usado
        temperature=0.2, # Baixa temperatura para respostas mais precisas
        max_tokens=500 # Limite de tokens na resposta
    )

def obter_base_vetores_da_url(url):
    """Carrega o conte√∫do de um website, divide o texto em peda√ßos e cria uma base vetorial a partir do conte√∫do."""
    # Carrega o conte√∫do do website
    carregador = WebBaseLoader(url)
    documento = carregador.load()

    # Divide o texto em peda√ßos menores para an√°lise
    divisor_texto = RecursiveCharacterTextSplitter()
    pedacos_documento = divisor_texto.split_documents(documento)

    # Configura o modelo de embeddings
    modelo_embeddings = HuggingFaceEmbeddings(
        model_name='sentence-transformers/all-MiniLM-L6-v2', # Modelo a ser usado
        model_kwargs={'device': 'cpu'}, # Usa CPU para processamento
        encode_kwargs={'normalize_embeddings': False} # N√£o normaliza os embeddings
    )

    # Cria a base vetorial para armazenar embeddings
    base_vetores = FAISS.from_documents(pedacos_documento, modelo_embeddings)
    return base_vetores

def obter_cadeia_recuperador_contexto(base_vetores):
    """Configura uma cadeia de recupera√ß√£o de contexto baseada no hist√≥rico de conversa√ß√£o."""
    # Inicializa o modelo de linguagem
    modelo = inicializar_modelo_llm()

    # Define o recuperador de documentos baseado na base vetorial
    recuperador = base_vetores.as_retriever()

    # Configura o prompt para gera√ß√£o de consultas de busca
    prompt = ChatPromptTemplate.from_messages([
        MessagesPlaceholder(variable_name='chat_history'),
        ('user', '{input}'),
        ('user', 'Com base na conversa acima, gere uma consulta de busca para encontrar informa√ß√µes relevantes')
    ])

    # Cria a cadeia de recupera√ß√£o sens√≠vel ao hist√≥rico de chat
    cadeia_recuperador = create_history_aware_retriever(modelo, recuperador, prompt)
    return cadeia_recuperador

def obter_cadeia_rag_conversacional(cadeia_recuperador):
    """Configura a cadeia de RAG conversacional para gerar respostas baseadas no contexto recuperado."""
    # Inicializa o modelo de linguagem
    modelo = inicializar_modelo_llm()

    # Configura o prompt para gera√ß√£o de respostas
    prompt = ChatPromptTemplate.from_messages([
        ('system', 'Responda √†s perguntas do usu√°rio com base no contexto abaixo:\n\n{context}'),
        MessagesPlaceholder(variable_name='chat_history'),
        ('user', '{input}')
    ])

    # Cria a cadeia para processar documentos
    cadeia_processar_documentos = create_stuff_documents_chain(modelo, prompt)

    # Retorna a cadeia de recupera√ß√£o integrada
    return create_retrieval_chain(cadeia_recuperador, cadeia_processar_documentos)

def obter_resposta(entrada_usuario):
    """Processa a entrada do usu√°rio e retorna a resposta do chatbot."""
    # Obt√©m as cadeias de recupera√ß√£o e RAG
    cadeia_recuperador = obter_cadeia_recuperador_contexto(st.session_state.base_vetores)
    cadeia_rag_conversacional = obter_cadeia_rag_conversacional(cadeia_recuperador)

    # Processa a entrada do usu√°rio e retorna a resposta gerada
    resposta = cadeia_rag_conversacional.invoke({
        'chat_history': st.session_state.historico_chat,
        'input': entrada_usuario
    })

    return resposta['answer']

def main():
    """
    Fun√ß√£o principal para configurar e executar a interface da aplica√ß√£o Streamlit.
    """
    # Configura o t√≠tulo e √≠cone da p√°gina
    st.set_page_config(page_title='Chat com websites', page_icon='ü§ñ')
    st.title('Chat com websites')

    # Configura a barra lateral para entrada da URL
    with st.sidebar:
        st.header('Configura√ß√µes')
        url_website = st.text_input('URL do website')

    # Verifica se a URL foi inserida
    if url_website is None or url_website == '':
        st.info('Por favor, insira a URL de um website')
    else:
         # Inicializa o hist√≥rico de conversa√ß√£o na sess√£o, se necess√°rio
        if 'historico_chat' not in st.session_state:
            st.session_state.historico_chat = [
                AIMessage(content='Ol√°, sou um bot. Como posso ajudar?')
            ]

        # Inicializa a base vetorial, se ainda n√£o existente
        if 'base_vetores' not in st.session_state:
            with st.spinner('Gerando o banco vetorial. Isso pode levar alguns minutos...'):
                st.session_state.base_vetores = obter_base_vetores_da_url(url_website)
            st.success('Banco vetorial gerado com sucesso!')

        # Captura a entrada do usu√°rio
        consulta_usuario = st.chat_input('Digite sua mensagem aqui...')

        # Processa e armazena a mensagem do usu√°rio e a resposta do chatbot
        if consulta_usuario is not None and consulta_usuario != '':
            resposta = obter_resposta(consulta_usuario)
            st.session_state.historico_chat.append(HumanMessage(content=consulta_usuario))
            st.session_state.historico_chat.append(AIMessage(content=resposta))

        # Exibe o hist√≥rico da conversa no chat
        for mensagem in st.session_state.historico_chat:
            if isinstance(mensagem, AIMessage):
                with st.chat_message('ai'):
                    st.write(mensagem.content)
            elif isinstance(mensagem, HumanMessage):
                with st.chat_message('human'):
                    st.write(mensagem.content)

# Executa a aplica√ß√£o se o script for chamado diretamente
if __name__ == '__main__':
    main()